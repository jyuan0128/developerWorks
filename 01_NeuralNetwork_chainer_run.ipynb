{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01_NeuralNetwork_chainer_run.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/jyuan0128/developerWorks/blob/master/01_NeuralNetwork_chainer_run.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "FCWsTzQXtZI7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Chainerによるニューラルネットワーク\n",
        "\n",
        "##本チュートリアルではchainerを利用してニューラルネットワークの実装を確認，学習および評価を行います．　環境としてはGoogle が提供する Google Colaboratory上でおこないます．"
      ]
    },
    {
      "metadata": {
        "id": "30MMRPy8tzWt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Goolge Colaboratory上にChainerとCupyをインストールします．"
      ]
    },
    {
      "metadata": {
        "id": "jInqoRpvuIOy",
        "colab_type": "code",
        "outputId": "074abeb9-cc05-494d-ec0e-3bdf44b238ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1173
        }
      },
      "cell_type": "code",
      "source": [
        "!curl https://colab.chainer.org/install | sh -"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  1379  100  1379    0     0   7747      0 --:--:-- --:--:-- --:--:--  7747\n",
            "+ apt -y -q install cuda-libraries-dev-9-2\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "The following additional packages will be installed:\n",
            "  cuda-cublas-dev-9-2 cuda-cufft-dev-9-2 cuda-curand-dev-9-2\n",
            "  cuda-cusolver-dev-9-2 cuda-cusparse-dev-9-2 cuda-npp-dev-9-2\n",
            "  cuda-nvgraph-dev-9-2 cuda-nvrtc-dev-9-2\n",
            "The following NEW packages will be installed:\n",
            "  cuda-cublas-dev-9-2 cuda-cufft-dev-9-2 cuda-curand-dev-9-2\n",
            "  cuda-cusolver-dev-9-2 cuda-cusparse-dev-9-2 cuda-libraries-dev-9-2\n",
            "  cuda-npp-dev-9-2 cuda-nvgraph-dev-9-2 cuda-nvrtc-dev-9-2\n",
            "0 upgraded, 9 newly installed, 0 to remove and 2 not upgraded.\n",
            "Need to get 332 MB of archives.\n",
            "After this operation, 972 MB of additional disk space will be used.\n",
            "Get:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1710/x86_64  cuda-cublas-dev-9-2 9.2.148.1-1 [50.4 MB]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1710/x86_64  cuda-cufft-dev-9-2 9.2.148-1 [106 MB]\n",
            "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1710/x86_64  cuda-curand-dev-9-2 9.2.148-1 [57.8 MB]\n",
            "Get:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1710/x86_64  cuda-cusolver-dev-9-2 9.2.148-1 [8,184 kB]\n",
            "Get:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1710/x86_64  cuda-cusparse-dev-9-2 9.2.148-1 [27.8 MB]\n",
            "Get:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1710/x86_64  cuda-nvrtc-dev-9-2 9.2.148-1 [9,348 B]\n",
            "Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1710/x86_64  cuda-nvgraph-dev-9-2 9.2.148-1 [30.1 MB]\n",
            "Get:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1710/x86_64  cuda-npp-dev-9-2 9.2.148-1 [52.0 MB]\n",
            "Get:9 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1710/x86_64  cuda-libraries-dev-9-2 9.2.148-1 [2,598 B]\n",
            "Fetched 332 MB in 10s (33.9 MB/s)\n",
            "Selecting previously unselected package cuda-cublas-dev-9-2.\n",
            "(Reading database ... 22280 files and directories currently installed.)\n",
            "Preparing to unpack .../0-cuda-cublas-dev-9-2_9.2.148.1-1_amd64.deb ...\n",
            "Unpacking cuda-cublas-dev-9-2 (9.2.148.1-1) ...\n",
            "Selecting previously unselected package cuda-cufft-dev-9-2.\n",
            "Preparing to unpack .../1-cuda-cufft-dev-9-2_9.2.148-1_amd64.deb ...\n",
            "Unpacking cuda-cufft-dev-9-2 (9.2.148-1) ...\n",
            "Selecting previously unselected package cuda-curand-dev-9-2.\n",
            "Preparing to unpack .../2-cuda-curand-dev-9-2_9.2.148-1_amd64.deb ...\n",
            "Unpacking cuda-curand-dev-9-2 (9.2.148-1) ...\n",
            "Selecting previously unselected package cuda-cusolver-dev-9-2.\n",
            "Preparing to unpack .../3-cuda-cusolver-dev-9-2_9.2.148-1_amd64.deb ...\n",
            "Unpacking cuda-cusolver-dev-9-2 (9.2.148-1) ...\n",
            "Selecting previously unselected package cuda-cusparse-dev-9-2.\n",
            "Preparing to unpack .../4-cuda-cusparse-dev-9-2_9.2.148-1_amd64.deb ...\n",
            "Unpacking cuda-cusparse-dev-9-2 (9.2.148-1) ...\n",
            "Selecting previously unselected package cuda-nvrtc-dev-9-2.\n",
            "Preparing to unpack .../5-cuda-nvrtc-dev-9-2_9.2.148-1_amd64.deb ...\n",
            "Unpacking cuda-nvrtc-dev-9-2 (9.2.148-1) ...\n",
            "Selecting previously unselected package cuda-nvgraph-dev-9-2.\n",
            "Preparing to unpack .../6-cuda-nvgraph-dev-9-2_9.2.148-1_amd64.deb ...\n",
            "Unpacking cuda-nvgraph-dev-9-2 (9.2.148-1) ...\n",
            "Selecting previously unselected package cuda-npp-dev-9-2.\n",
            "Preparing to unpack .../7-cuda-npp-dev-9-2_9.2.148-1_amd64.deb ...\n",
            "Unpacking cuda-npp-dev-9-2 (9.2.148-1) ...\n",
            "Selecting previously unselected package cuda-libraries-dev-9-2.\n",
            "Preparing to unpack .../8-cuda-libraries-dev-9-2_9.2.148-1_amd64.deb ...\n",
            "Unpacking cuda-libraries-dev-9-2 (9.2.148-1) ...\n",
            "Setting up cuda-npp-dev-9-2 (9.2.148-1) ...\n",
            "Setting up cuda-curand-dev-9-2 (9.2.148-1) ...\n",
            "Setting up cuda-nvrtc-dev-9-2 (9.2.148-1) ...\n",
            "Setting up cuda-cusolver-dev-9-2 (9.2.148-1) ...\n",
            "Setting up cuda-cufft-dev-9-2 (9.2.148-1) ...\n",
            "Setting up cuda-cusparse-dev-9-2 (9.2.148-1) ...\n",
            "Setting up cuda-cublas-dev-9-2 (9.2.148.1-1) ...\n",
            "Setting up cuda-nvgraph-dev-9-2 (9.2.148-1) ...\n",
            "Setting up cuda-libraries-dev-9-2 (9.2.148-1) ...\n",
            "+ pip install -q cupy-cuda92  chainer \n",
            "+ set +ex\n",
            "Installation succeeded!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4Esf4xv7uoEr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Chainerでニューラルネットワークを学習するために必要なモジュールや関数をインポートします．"
      ]
    },
    {
      "metadata": {
        "id": "7qolZekhukSL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import chainer\n",
        "from chainer import Chain, Variable\n",
        "import chainer.functions as F\n",
        "import chainer.links as L\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HZMFh6Nk0AtL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "chainerのバージョンを確認します．"
      ]
    },
    {
      "metadata": {
        "id": "zt_lJUrEz5-S",
        "colab_type": "code",
        "outputId": "d7c3fd92-cf8d-488e-d5e3-b36abb22a9c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "chainer.__version__"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'5.0.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "5kYv__Gv8DgC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "次に学習データを読み込みます．MNISTデータセットはチュートリアルでよく利用されるデータセットであり，chainerではMNISTデータセットを取得し，学習するためのフォーマットに変換してくれます．データセットには学習用とテスト用のデータに分かれており，それぞれtrain_dataset, test_datasetとします．また，それらには画像データと教師ラベルがあり，それらをtrain_xとtrain_y，test_xとtest_yとします．"
      ]
    },
    {
      "metadata": {
        "id": "nCv8tqrY76Ug",
        "colab_type": "code",
        "outputId": "07d9c269-d35c-42dc-856a-fc621aebac07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "train_dataset, test_dataset = chainer.datasets.get_mnist()\n",
        "train_x,train_y = train_dataset._datasets\n",
        "test_x, test_y = test_dataset._datasets"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading from http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz...\n",
            "Downloading from http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz...\n",
            "Downloading from http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz...\n",
            "Downloading from http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz...\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "2efIxj2UB4EM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "学習データのサイズを確認します．学習データ数は6万枚，１つのデータのサイズは784次元となっています．"
      ]
    },
    {
      "metadata": {
        "id": "-YTEPjI18Eb_",
        "colab_type": "code",
        "outputId": "337311ce-f06a-436d-f499-49609e7e5c05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print (train_x.shape, train_y.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 784) (60000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DbtGxSpZ2Iv_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "MNISTデータセットに含まれる画像を表示してみます．ここでは，matplotlibで複数の画像を表示させるプログラムを利用します．"
      ]
    },
    {
      "metadata": {
        "id": "I9AilV_LxHBV",
        "colab_type": "code",
        "outputId": "a2562530-bce3-4e86-a2ff-fdfd3ed3bb65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import os.path\n",
        "\n",
        "cols =10\n",
        "\n",
        "def clearLabel(_ax):\n",
        "  _ax.tick_params(labelbottom=\"off\",bottom=\"off\")\n",
        "  _ax.tick_params(labelleft=\"off\",left=\"off\")\n",
        "  _ax.set_xticklabels([]) \n",
        "  _ax.axis('off')\n",
        "  return _ax\n",
        "\n",
        "def readImage(idx):\n",
        "    bimg = train_x[idx].copy()\n",
        "    label = train_y[idx]\n",
        "    bimg = bimg.reshape(28,28)\n",
        "    return bimg\n",
        "\n",
        "  \n",
        "fig = plt.figure()\n",
        "\n",
        "for c in range(cols):\n",
        "    ax1 = fig.add_subplot(1, cols, c+1)\n",
        "    clearLabel(ax1)\n",
        "    show_img1 = readImage(c)\n",
        "    plt.gray()\n",
        "    plt.imshow(show_img1)\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcwAAAA0CAYAAAAHbQhGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f8266174e48>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "o05arGVVu8Uq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "ニューラルネットワークを定義します．ここでは，入力層，中間層，出力層から構成される３層のニューラルネットワークとします．入力層のユニット数は入力データのサイズによります．ここではNoneとし，データにより変更できるようにしておきます．中間層と出力層のユニット数は引数として与え，それぞれn_units，n_outとします． Chainerでは，\\__init\\__関数にこれらの引数を与えて各層を定義します．各層はlinear関数としています．これは全結合層を意味しています．そして，\\__call\\__関数で定義した層を接続して処理するように記述します．\\__call\\__関数の引数xは入力データです．それを\\__init\\__関数で定義したl1という中間層に与え，その出力を活性化関数であるrelu関数に与えます．その出力をh1としています．h1は出力層h2に与えられ，その出力をh2としています．"
      ]
    },
    {
      "metadata": {
        "id": "g4hAwTlKuzVT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class NN(chainer.Chain):\n",
        "    def __init__(self, n_units, n_out):\n",
        "        super().__init__(\n",
        "            l1=L.Linear(None, n_units),\n",
        "            l2=L.Linear(n_units, n_out),\n",
        "        )\n",
        "\n",
        "    def __call__(self, x):\n",
        "        h1 = F.relu(self.l1(x))\n",
        "        return self.l2(h1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "B5pf-b73773n",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "中間層と出力層のユニット数を定義します．ここでは中間層のユニット数を50，出力層のユニット数を10とします．"
      ]
    },
    {
      "metadata": {
        "id": "kFGiW2Sy77a_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "n_units = 50\n",
        "out_units = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-hYTV75a79OS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "各層のユニット数をNN関数の引数として与え，ネットワークモデルを定義します．学習を行う際の最適化方法としてモーメンタムSGD(モーメンタム付き確率的勾配降下法）を利用します．また，学習率を0.01，モーメンタムを0.9として引数に与えます．そして，最適化方法のsetup関数にネットワークモデルを与えます．"
      ]
    },
    {
      "metadata": {
        "id": "-rdmJMVY75vq",
        "colab_type": "code",
        "outputId": "92a24c40-7609-49c8-fa2f-bc75f1cf1a4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "model = NN(n_units, out_units)\n",
        "optimizer = chainer.optimizers.MomentumSGD(lr=0.01, momentum=0.9)\n",
        "optimizer.setup(model)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<chainer.optimizers.momentum_sgd.MomentumSGD at 0x7f825b783128>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "metadata": {
        "id": "MUNa9Xe79vAG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "１回の誤差を算出するデータ数（ミニバッチサイズ）を100，学習エポック数を100とします．"
      ]
    },
    {
      "metadata": {
        "id": "iRdLBp8y3sho",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size = 100\n",
        "epoch_num = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-MqviyB23uf3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "MNISTの学習データサイズを取得し，１エポック内における更新回数を求めます．学習データは毎エポックでランダムに利用するため，numpyのpermutationという関数を利用します．各更新において，学習用データと教師データをそれぞれxとtとします．学習モデルにxを与えて各クラスの確率yを取得します．各クラスの確率yと教師ラベルtとの誤差をsoftmax coross entropy誤差関数で算出します．また，認識精度も算出します．そして，誤差をbackward関数で逆伝播し，ネットワークの更新を行います．"
      ]
    },
    {
      "metadata": {
        "id": "68RE3RTa76-W",
        "colab_type": "code",
        "outputId": "492d11d8-3944-4222-877f-5a5cad5cf57d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "cell_type": "code",
      "source": [
        "train_data_num = train_x.shape[0]\n",
        "iter_one_epoch = int(train_x.shape[0]/batch_size)\n",
        "for epoch in range(epoch_num):\n",
        "        sum_loss = 0\n",
        "        sum_accuracy = 0\n",
        "        perm = np.random.permutation(train_data_num)\n",
        "        for i in range(0, train_data_num, batch_size):\n",
        "                x = Variable(train_x[perm[i:i+batch_size]])\n",
        "                t = Variable(train_y[perm[i:i+batch_size]])\n",
        "                y = model(x)        \n",
        "                model.zerograds()\n",
        "                loss = F.softmax_cross_entropy(y, t)\n",
        "                acc = F.accuracy(y, t)\n",
        "                loss.backward()\n",
        "                optimizer.update()\n",
        "                sum_loss += loss.data*batch_size\n",
        "                sum_accuracy += acc.data*batch_size\n",
        "        print(\"epoch: {}, mean loss: {}, mean accuracy: {}\".format(epoch+1, sum_loss/train_data_num, sum_accuracy/train_data_num))\n",
        "    \n",
        "    "
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 1, mean loss: 0.49045873696605363, mean accuracy: 0.8664666673541069\n",
            "epoch: 2, mean loss: 0.269239149056375, mean accuracy: 0.9240500019987424\n",
            "epoch: 3, mean loss: 0.22060017596930265, mean accuracy: 0.9375166694323221\n",
            "epoch: 4, mean loss: 0.18639487159748871, mean accuracy: 0.9473000002900759\n",
            "epoch: 5, mean loss: 0.16118786424398424, mean accuracy: 0.9546500028173128\n",
            "epoch: 6, mean loss: 0.14379235561316212, mean accuracy: 0.9591333367427191\n",
            "epoch: 7, mean loss: 0.12958766938187183, mean accuracy: 0.9634833389520645\n",
            "epoch: 8, mean loss: 0.11875385965841512, mean accuracy: 0.9660000064969063\n",
            "epoch: 9, mean loss: 0.11014389376156032, mean accuracy: 0.9686000064015389\n",
            "epoch: 10, mean loss: 0.10281845670193433, mean accuracy: 0.9713666751980782\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "b6OZY7GgDBPl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "学習できたネットワークモデルを利用して評価を行います．"
      ]
    },
    {
      "metadata": {
        "id": "03_8Wh5V9F6V",
        "colab_type": "code",
        "outputId": "917a9f59-3161-400e-ec08-b06fe5133639",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "cnt = 0\n",
        "test_data_num = test_x.shape[0]\n",
        "for i in range(test_data_num):\n",
        "    x = Variable(np.array([test_x[i]], dtype=np.float32))\n",
        "    t = test_y[i]\n",
        "    y = model(x)\n",
        "    y = np.argmax(y.data[0])\n",
        "    if t == y:\n",
        "        cnt += 1\n",
        " \n",
        "print(\"test accuracy: {}\".format(cnt/test_data_num))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test accuracy: 0.9672\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cxO7tnfWDHMJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 課題　\n",
        "###以下の課題に取り組みましょう"
      ]
    },
    {
      "metadata": {
        "id": "knno-MVZ4Oye",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "1  ネットワーク構造を変えて実験しましょう． \n",
        "\n",
        "   まず，中間層のユニット数を200個にしましょう．\n",
        "   \n",
        "   次に，中間層を1層増やしましょう．その際， 中間層のユニット数は200個としましょう．"
      ]
    },
    {
      "metadata": {
        "id": "udCSibNwhjtm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "c9d33855-7c2d-4fb1-d4cc-bd4b04cbb447"
      },
      "cell_type": "code",
      "source": [
        "n_units = 200\n",
        "model = NN(n_units, out_units)\n",
        "optimizer = chainer.optimizers.MomentumSGD(lr=0.01, momentum=0.9)\n",
        "optimizer.setup(model)\n",
        "\n",
        "train_data_num = train_x.shape[0]\n",
        "iter_one_epoch = int(train_x.shape[0]/batch_size)\n",
        "for epoch in range(epoch_num):\n",
        "        sum_loss = 0\n",
        "        sum_accuracy = 0\n",
        "        perm = np.random.permutation(train_data_num)\n",
        "        for i in range(0, train_data_num, batch_size):\n",
        "                x = Variable(train_x[perm[i:i+batch_size]])\n",
        "                t = Variable(train_y[perm[i:i+batch_size]])\n",
        "                y = model(x)        \n",
        "                model.zerograds()\n",
        "                loss = F.softmax_cross_entropy(y, t)\n",
        "                acc = F.accuracy(y, t)\n",
        "                loss.backward()\n",
        "                optimizer.update()\n",
        "                sum_loss += loss.data*batch_size\n",
        "                sum_accuracy += acc.data*batch_size\n",
        "        print(\"epoch: {}, mean loss: {}, mean accuracy: {}\".format(epoch+1, sum_loss/train_data_num, sum_accuracy/train_data_num))\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 1, mean loss: 0.48499074575801693, mean accuracy: 0.868200001269579\n",
            "epoch: 2, mean loss: 0.24341461749126514, mean accuracy: 0.9308333347241083\n",
            "epoch: 3, mean loss: 0.18917635112379988, mean accuracy: 0.9462000015377998\n",
            "epoch: 4, mean loss: 0.15628758880620203, mean accuracy: 0.9555333350102106\n",
            "epoch: 5, mean loss: 0.13320058987786373, mean accuracy: 0.9621166703104973\n",
            "epoch: 6, mean loss: 0.11632369552118083, mean accuracy: 0.9673666723569234\n",
            "epoch: 7, mean loss: 0.10311739737788836, mean accuracy: 0.9712000072995821\n",
            "epoch: 8, mean loss: 0.09268048759549856, mean accuracy: 0.974350009461244\n",
            "epoch: 9, mean loss: 0.08383879527760049, mean accuracy: 0.9762333431839942\n",
            "epoch: 10, mean loss: 0.07642272892408072, mean accuracy: 0.9785833442211151\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OlU-NYeNiVbU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0d9e94ab-0d4a-4d72-b6b3-a3c5ba4ba913"
      },
      "cell_type": "code",
      "source": [
        "cnt = 0\n",
        "test_data_num = test_x.shape[0]\n",
        "for i in range(test_data_num):\n",
        "    x = Variable(np.array([test_x[i]], dtype=np.float32))\n",
        "    t = test_y[i]\n",
        "    y = model(x)\n",
        "    y = np.argmax(y.data[0])\n",
        "    if t == y:\n",
        "        cnt += 1\n",
        " \n",
        "print(\"test accuracy1: {}\".format(cnt/test_data_num))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test accuracy1: 0.9726\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "woQ4Ew-SikaF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class NN(chainer.Chain):\n",
        "    def __init__(self, n_units, n_out):\n",
        "        super().__init__(\n",
        "            l1=L.Linear(None, n_units),\n",
        "            l2=L.Linear(n_units, n_units),\n",
        "            l3=L.Linear(n_units, n_out),\n",
        "        )\n",
        "\n",
        "    def __call__(self, x):\n",
        "        h1 = F.relu(self.l1(x))\n",
        "        return self.l2(h1)\n",
        "        h2 = F.relu(self.l2(x))\n",
        "        return self.l3(h1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1rnkksOfj1MV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "0839e5c4-6056-473d-e028-0b40885e2e30"
      },
      "cell_type": "code",
      "source": [
        "n_units = 200\n",
        "model = NN(n_units, out_units)\n",
        "optimizer = chainer.optimizers.MomentumSGD(lr=0.01, momentum=0.9)\n",
        "optimizer.setup(model)\n",
        "\n",
        "train_data_num = train_x.shape[0]\n",
        "iter_one_epoch = int(train_x.shape[0]/batch_size)\n",
        "for epoch in range(epoch_num):\n",
        "        sum_loss = 0\n",
        "        sum_accuracy = 0\n",
        "        perm = np.random.permutation(train_data_num)\n",
        "        for i in range(0, train_data_num, batch_size):\n",
        "                x = Variable(train_x[perm[i:i+batch_size]])\n",
        "                t = Variable(train_y[perm[i:i+batch_size]])\n",
        "                y = model(x)        \n",
        "                model.zerograds()\n",
        "                loss = F.softmax_cross_entropy(y, t)\n",
        "                acc = F.accuracy(y, t)\n",
        "                loss.backward()\n",
        "                optimizer.update()\n",
        "                sum_loss += loss.data*batch_size\n",
        "                sum_accuracy += acc.data*batch_size\n",
        "        print(\"epoch: {}, mean loss: {}, mean accuracy: {}\".format(epoch+1, sum_loss/train_data_num, sum_accuracy/train_data_num))\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 1, mean loss: 0.5676414292057356, mean accuracy: 0.8549666687225302\n",
            "epoch: 2, mean loss: 0.2643198122580846, mean accuracy: 0.9249000010887781\n",
            "epoch: 3, mean loss: 0.21042744527260462, mean accuracy: 0.9398833348353703\n",
            "epoch: 4, mean loss: 0.17328375509629648, mean accuracy: 0.9509166676799456\n",
            "epoch: 5, mean loss: 0.14818446133906643, mean accuracy: 0.9581833363572756\n",
            "epoch: 6, mean loss: 0.1282019355800003, mean accuracy: 0.9642500057816505\n",
            "epoch: 7, mean loss: 0.11404418509143094, mean accuracy: 0.9674000055591265\n",
            "epoch: 8, mean loss: 0.10190373113689323, mean accuracy: 0.9716000081102053\n",
            "epoch: 9, mean loss: 0.09226280067116022, mean accuracy: 0.9741500094532967\n",
            "epoch: 10, mean loss: 0.08402511795982719, mean accuracy: 0.9765000090003013\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_G2gozkalSYH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0dff3a7c-3786-45ba-f13c-4e99355730be"
      },
      "cell_type": "code",
      "source": [
        "cnt = 0\n",
        "test_data_num = test_x.shape[0]\n",
        "for i in range(test_data_num):\n",
        "    x = Variable(np.array([test_x[i]], dtype=np.float32))\n",
        "    t = test_y[i]\n",
        "    y = model(x)\n",
        "    y = np.argmax(y.data[0])\n",
        "    if t == y:\n",
        "        cnt += 1\n",
        " \n",
        "print(\"test accuracy2: {}\".format(cnt/test_data_num))\n",
        "\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test accuracy2: 0.9723\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5oYzfKGU4Idy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "2  最適化の方法をAdamに変えて実験しましょう．\n"
      ]
    },
    {
      "metadata": {
        "id": "vT8h6w1hP5wU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "7aeda75b-7cad-4643-de78-47c1590d9a73"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "n_units = 200\n",
        "out_units = 10\n",
        "batch_size = 100\n",
        "epoch_num = 10\n",
        "model = NN(n_units, out_units)\n",
        "optimizer = chainer.optimizers.Adam(alpha=0.001, beta1=0.9, beta2=0.999, eps=1e-08, eta=1.0, weight_decay_rate=0, amsgrad=False)\n",
        "optimizer.setup(model)\n",
        "\n",
        "train_data_num = train_x.shape[0]\n",
        "iter_one_epoch = int(train_x.shape[0]/batch_size)\n",
        "for epoch in range(epoch_num):\n",
        "        sum_loss = 0\n",
        "        sum_accuracy = 0\n",
        "        perm = np.random.permutation(train_data_num)\n",
        "        for i in range(0, train_data_num, batch_size):\n",
        "                x = Variable(train_x[perm[i:i+batch_size]])\n",
        "                t = Variable(train_y[perm[i:i+batch_size]])\n",
        "                y = model(x)        \n",
        "                model.zerograds()\n",
        "                loss = F.softmax_cross_entropy(y, t)\n",
        "                acc = F.accuracy(y, t)\n",
        "                loss.backward()\n",
        "                optimizer.update()\n",
        "                sum_loss += loss.data*batch_size\n",
        "                sum_accuracy += acc.data*batch_size\n",
        "        print(\"epoch: {}, mean loss: {}, mean accuracy: {}\".format(epoch+1, sum_loss/train_data_num, sum_accuracy/train_data_num))\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 1, mean loss: 0.4130255226418376, mean accuracy: 0.8954666676217069\n",
            "epoch: 2, mean loss: 0.16445619848246376, mean accuracy: 0.9525166709224383\n",
            "epoch: 3, mean loss: 0.11626727827824652, mean accuracy: 0.966366672317187\n",
            "epoch: 4, mean loss: 0.08809340780911347, mean accuracy: 0.9739666760961214\n",
            "epoch: 5, mean loss: 0.06919455116614699, mean accuracy: 0.9796500106652578\n",
            "epoch: 6, mean loss: 0.05646069781001036, mean accuracy: 0.983733344177405\n",
            "epoch: 7, mean loss: 0.045421093471813945, mean accuracy: 0.9870500096678734\n",
            "epoch: 8, mean loss: 0.03715018491571148, mean accuracy: 0.989216675957044\n",
            "epoch: 9, mean loss: 0.031009849311473468, mean accuracy: 0.9911000076929728\n",
            "epoch: 10, mean loss: 0.024501739629001047, mean accuracy: 0.9933333393931388\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uoKqIxxnjlJR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fca43693-ad54-4151-d602-8f197333efa9"
      },
      "cell_type": "code",
      "source": [
        "cnt = 0\n",
        "test_data_num = test_x.shape[0]\n",
        "for i in range(test_data_num):\n",
        "    x = Variable(np.array([test_x[i]], dtype=np.float32))\n",
        "    t = test_y[i]\n",
        "    y = model(x)\n",
        "    y = np.argmax(y.data[0])\n",
        "    if t == y:\n",
        "        cnt += 1\n",
        " \n",
        "print(\"test accuracy3: {}\".format(cnt/test_data_num))\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test accuracy3: 0.9627\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yyGUUy9p4Nwi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "3  エポック数やミニバッチサイズを変えて実験しましょう．\n",
        "\n",
        "  まず，ミニバッチサイズを128にしましょう．\n",
        "  \n",
        "  次に，エポック数を50にしましょう．"
      ]
    },
    {
      "metadata": {
        "id": "mYrDFh6kj2mb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "5b427f3b-2311-41b0-c67f-ce414532ca1f"
      },
      "cell_type": "code",
      "source": [
        "batch_size =128\n",
        "train_data_num = train_x.shape[0]\n",
        "iter_one_epoch = int(train_x.shape[0]/batch_size)\n",
        "for epoch in range(epoch_num):\n",
        "        sum_loss = 0\n",
        "        sum_accuracy = 0\n",
        "        perm = np.random.permutation(train_data_num)\n",
        "        for i in range(0, train_data_num, batch_size):\n",
        "                x = Variable(train_x[perm[i:i+batch_size]])\n",
        "                t = Variable(train_y[perm[i:i+batch_size]])\n",
        "                y = model(x)        \n",
        "                model.zerograds()\n",
        "                loss = F.softmax_cross_entropy(y, t)\n",
        "                acc = F.accuracy(y, t)\n",
        "                loss.backward()\n",
        "                optimizer.update()\n",
        "                sum_loss += loss.data*batch_size\n",
        "                sum_accuracy += acc.data*batch_size\n",
        "        print(\"epoch: {}, mean loss: {}, mean accuracy: {}\".format(epoch+1, sum_loss/train_data_num, sum_accuracy/train_data_num))\n",
        "        \n",
        "\n",
        "cnt = 0\n",
        "test_data_num = test_x.shape[0]\n",
        "for i in range(test_data_num):\n",
        "    x = Variable(np.array([test_x[i]], dtype=np.float32))\n",
        "    t = test_y[i]\n",
        "    y = model(x)\n",
        "    y = np.argmax(y.data[0])\n",
        "    if t == y:\n",
        "        cnt += 1\n",
        " \n",
        "print(\"test accuracy4: {}\".format(cnt/test_data_num))\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 1, mean loss: 0.5425036308606466, mean accuracy: 0.8504944444020589\n",
            "epoch: 2, mean loss: 0.28444726711908974, mean accuracy: 0.9194111110687256\n",
            "epoch: 3, mean loss: 0.2371968441963196, mean accuracy: 0.9327611110687256\n",
            "epoch: 4, mean loss: 0.20714781770706175, mean accuracy: 0.9418666666666666\n",
            "epoch: 5, mean loss: 0.18480735749403635, mean accuracy: 0.9486611110687256\n",
            "epoch: 6, mean loss: 0.16717538561820983, mean accuracy: 0.9533944444020589\n",
            "epoch: 7, mean loss: 0.15233015751043955, mean accuracy: 0.9573611110687256\n",
            "epoch: 8, mean loss: 0.14040881896813712, mean accuracy: 0.9611166666666666\n",
            "epoch: 9, mean loss: 0.13036216554641725, mean accuracy: 0.96345\n",
            "epoch: 10, mean loss: 0.12166366636753083, mean accuracy: 0.9660388889312744\n",
            "test accuracy4: 0.9627\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "etIBAO2LkgNR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 884
        },
        "outputId": "320ba998-539f-490f-894f-acd5003e03f0"
      },
      "cell_type": "code",
      "source": [
        "epoch_num = 50\n",
        "train_data_num = train_x.shape[0]\n",
        "iter_one_epoch = int(train_x.shape[0]/batch_size)\n",
        "for epoch in range(epoch_num):\n",
        "        sum_loss = 0\n",
        "        sum_accuracy = 0\n",
        "        perm = np.random.permutation(train_data_num)\n",
        "        for i in range(0, train_data_num, batch_size):\n",
        "                x = Variable(train_x[perm[i:i+batch_size]])\n",
        "                t = Variable(train_y[perm[i:i+batch_size]])\n",
        "                y = model(x)        \n",
        "                model.zerograds()\n",
        "                loss = F.softmax_cross_entropy(y, t)\n",
        "                acc = F.accuracy(y, t)\n",
        "                loss.backward()\n",
        "                optimizer.update()\n",
        "                sum_loss += loss.data*batch_size\n",
        "                sum_accuracy += acc.data*batch_size\n",
        "        print(\"epoch: {}, mean loss: {}, mean accuracy: {}\".format(epoch+1, sum_loss/train_data_num, sum_accuracy/train_data_num))\n",
        "        \n",
        "\n",
        "cnt = 0\n",
        "test_data_num = test_x.shape[0]\n",
        "for i in range(test_data_num):\n",
        "    x = Variable(np.array([test_x[i]], dtype=np.float32))\n",
        "    t = test_y[i]\n",
        "    y = model(x)\n",
        "    y = np.argmax(y.data[0])\n",
        "    if t == y:\n",
        "        cnt += 1\n",
        " \n",
        "print(\"test accuracy5: {}\".format(cnt/test_data_num))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 1, mean loss: 0.11419536668459575, mean accuracy: 0.9682611110687256\n",
            "epoch: 2, mean loss: 0.10775599094629287, mean accuracy: 0.970044444402059\n",
            "epoch: 3, mean loss: 0.10114891945123672, mean accuracy: 0.9716833333333333\n",
            "epoch: 4, mean loss: 0.09655623219013214, mean accuracy: 0.9735166666666667\n",
            "epoch: 5, mean loss: 0.09195136585235596, mean accuracy: 0.9747277777353922\n",
            "epoch: 6, mean loss: 0.08744974750677745, mean accuracy: 0.9763611110687256\n",
            "epoch: 7, mean loss: 0.0836016128818194, mean accuracy: 0.976894444402059\n",
            "epoch: 8, mean loss: 0.08022422878344854, mean accuracy: 0.9773277777353923\n",
            "epoch: 9, mean loss: 0.07671629540125528, mean accuracy: 0.979094444402059\n",
            "epoch: 10, mean loss: 0.07353582992156346, mean accuracy: 0.9804277777353922\n",
            "epoch: 11, mean loss: 0.071002072874705, mean accuracy: 0.9810777777353923\n",
            "epoch: 12, mean loss: 0.06847844299475352, mean accuracy: 0.9816833333333334\n",
            "epoch: 13, mean loss: 0.0653943745692571, mean accuracy: 0.9824666666666667\n",
            "epoch: 14, mean loss: 0.06322463485797246, mean accuracy: 0.9834277777353923\n",
            "epoch: 15, mean loss: 0.06098648866017659, mean accuracy: 0.9837611110687255\n",
            "epoch: 16, mean loss: 0.059333993097146355, mean accuracy: 0.9841055555979411\n",
            "epoch: 17, mean loss: 0.05671006783246994, mean accuracy: 0.9849388889312745\n",
            "epoch: 18, mean loss: 0.055056841850280765, mean accuracy: 0.9856\n",
            "epoch: 19, mean loss: 0.053434863197803495, mean accuracy: 0.9861611110687256\n",
            "epoch: 20, mean loss: 0.0517786185781161, mean accuracy: 0.9863166666666666\n",
            "epoch: 21, mean loss: 0.05006443862915039, mean accuracy: 0.9871388889312744\n",
            "epoch: 22, mean loss: 0.04844815606673559, mean accuracy: 0.987655555597941\n",
            "epoch: 23, mean loss: 0.047433239511648816, mean accuracy: 0.9880722222646078\n",
            "epoch: 24, mean loss: 0.04591836169958115, mean accuracy: 0.9883333333333333\n",
            "epoch: 25, mean loss: 0.044348125123977664, mean accuracy: 0.98905\n",
            "epoch: 26, mean loss: 0.043138153461615245, mean accuracy: 0.9893944444020589\n",
            "epoch: 27, mean loss: 0.04206207791566849, mean accuracy: 0.9897166666666667\n",
            "epoch: 28, mean loss: 0.04093220044374466, mean accuracy: 0.9899277777353922\n",
            "epoch: 29, mean loss: 0.03941383651097616, mean accuracy: 0.9900333333333333\n",
            "epoch: 30, mean loss: 0.03865572906732559, mean accuracy: 0.9908944444020589\n",
            "epoch: 31, mean loss: 0.037613743257522585, mean accuracy: 0.991044444402059\n",
            "epoch: 32, mean loss: 0.036341938165823616, mean accuracy: 0.9913611110687256\n",
            "epoch: 33, mean loss: 0.03560941479206085, mean accuracy: 0.9913777777353923\n",
            "epoch: 34, mean loss: 0.03459259507258733, mean accuracy: 0.9918611110687255\n",
            "epoch: 35, mean loss: 0.03391753922303518, mean accuracy: 0.9922833333333333\n",
            "epoch: 36, mean loss: 0.032925889337062836, mean accuracy: 0.9924666666666667\n",
            "epoch: 37, mean loss: 0.0319168706536293, mean accuracy: 0.9925833333333334\n",
            "epoch: 38, mean loss: 0.03148940234184265, mean accuracy: 0.99305\n",
            "epoch: 39, mean loss: 0.030572980769475303, mean accuracy: 0.9932111110687256\n",
            "epoch: 40, mean loss: 0.02934412788748741, mean accuracy: 0.9935833333333334\n",
            "epoch: 41, mean loss: 0.028872588952382407, mean accuracy: 0.9937777777353922\n",
            "epoch: 42, mean loss: 0.027991199493408205, mean accuracy: 0.9941\n",
            "epoch: 43, mean loss: 0.027732448627551396, mean accuracy: 0.9941\n",
            "epoch: 44, mean loss: 0.02673619398276011, mean accuracy: 0.99455\n",
            "epoch: 45, mean loss: 0.02608314575354258, mean accuracy: 0.9946222222646077\n",
            "epoch: 46, mean loss: 0.025456425086657207, mean accuracy: 0.9949\n",
            "epoch: 47, mean loss: 0.024950305712223054, mean accuracy: 0.99515\n",
            "epoch: 48, mean loss: 0.02434663405418396, mean accuracy: 0.9952055555979411\n",
            "epoch: 49, mean loss: 0.023285544685522717, mean accuracy: 0.9957166666666667\n",
            "epoch: 50, mean loss: 0.02296691513856252, mean accuracy: 0.9957333333333334\n",
            "test accuracy5: 0.9721\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VpAVFj14pbdG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "ここまでの考察\n",
        "\n",
        "*   ネットワーク構造を変えてみると、少し精度が改善された\n",
        "*   最適化adamにした結果、もうちょっと改善（0.972->0.978）\n",
        "*   バッチサイズやエポックを変更した結果、悪化（過学習？）\n",
        "*   パラメータを調整することで、精度が変化する\n",
        "*   パラメータの調整とネットワークの構造が精度に影響している\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "C65RJO4L5LCX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##別のコードの書き方\n",
        "\n",
        "ここまでのコードは学習の流れをわかりやすくするために，エポックまたはミニバッチ毎にfor文で学習を行うようにプログラムを作成しました． chainerでは，trainerとupdaterという繰り返し処理を抽象化するクラスが用意されています．これらを利用した場合は，以下のように書くことができます．\n",
        "\n",
        "SerialIteratorにより学習および評価データを繰り返し取得することができます．　StarndardUpdaterは， SerialIteratorによって繰り返し取得したデータをoptimizerに渡してmodelをアップデートします． TrainerはこのUpdaterの処理を指定されたエポック回数分行い，学習したモデルをresultに保存できます． Trainerにはさまざなま拡張機能を追加できます．Evaluatorは学習したモデルを評価する機能であり，LogReportは学習時のロスは精度を記憶します．これらの記憶されているログをPlotReportが表示したりグラフとして保存したりします．　学習の実行はtrainerクラスのrun関数により行います．"
      ]
    },
    {
      "metadata": {
        "id": "WqmSOUHw51Jk",
        "colab_type": "code",
        "outputId": "f976979d-c811-4f86-a1ab-8972bd6a15ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "from chainer import training\n",
        "from chainer.training import extensions\n",
        "\n",
        "batch_size = 100\n",
        "epoch_num = 10\n",
        "\n",
        "n_units = 50\n",
        "out_units = 10\n",
        "\n",
        "model = L.Classifier(NN(n_units, out_units))\n",
        "optimizer = chainer.optimizers.MomentumSGD(lr=0.01, momentum=0.9)\n",
        "optimizer.setup(model)  \n",
        "  \n",
        "train_dataset, test_dataset = chainer.datasets.get_mnist()\n",
        "\n",
        "train_iter = chainer.iterators.SerialIterator(train_dataset, batch_size)\n",
        "test_iter = chainer.iterators.SerialIterator(test_dataset, batch_size,    repeat=False, shuffle=False)\n",
        "\n",
        "updater = training.updaters.StandardUpdater( train_iter, optimizer, device=-1)\n",
        "trainer = training.Trainer(updater, (epoch_num, 'epoch'), out='result')\n",
        "\n",
        "trainer.extend(extensions.Evaluator(test_iter, model, device=-1))\n",
        "\n",
        "trainer.extend(extensions.dump_graph('main/loss'))\n",
        "\n",
        "trainer.extend(extensions.LogReport())\n",
        "\n",
        "trainer.extend(extensions.PlotReport(['main/loss', 'validation/main/loss'],  'epoch', file_name='loss.png'))\n",
        "trainer.extend(extensions.PlotReport(['main/accuracy', 'validation/main/accuracy'],'epoch', file_name='accuracy.png'))\n",
        "trainer.extend(extensions.PrintReport(['epoch', 'main/loss', 'validation/main/loss', 'main/accuracy', 'validation/main/accuracy', 'elapsed_time']))\n",
        "\n",
        "trainer.run()\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch       main/loss   validation/main/loss  main/accuracy  validation/main/accuracy  elapsed_time\n",
            "\u001b[J1           0.563541    0.294832              0.8513         0.915                     3.13914       \n",
            "\u001b[J2           0.278634    0.242989              0.921333       0.9306                    6.71502       \n",
            "\u001b[J3           0.232631    0.204502              0.934083       0.9415                    10.3416       \n",
            "\u001b[J4           0.197345    0.181211              0.944367       0.9478                    13.9737       \n",
            "\u001b[J5           0.170985    0.160285              0.951917       0.9532                    17.5979       \n",
            "\u001b[J6           0.152192    0.148452              0.95695        0.9568                    21.2455       \n",
            "\u001b[J7           0.137362    0.137972              0.961333       0.9583                    24.8807       \n",
            "\u001b[J8           0.125364    0.128841              0.964333       0.9621                    28.5546       \n",
            "\u001b[J9           0.115452    0.123842              0.967133       0.963                     32.1666       \n",
            "\u001b[J10          0.108433    0.115712              0.968817       0.9653                    35.8072       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QtLyC9Cxstav",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 884
        },
        "outputId": "e126a5d7-1248-44c4-925d-17c6499e1d00"
      },
      "cell_type": "code",
      "source": [
        "batch_size = 100\n",
        "epoch_num = 50\n",
        "\n",
        "n_units = 200\n",
        "out_units = 10\n",
        "\n",
        "model = L.Classifier(NN(n_units, out_units))\n",
        "optimizer = chainer.optimizers.MomentumSGD(lr=0.01, momentum=0.9)\n",
        "optimizer.setup(model)  \n",
        "  \n",
        "train_dataset, test_dataset = chainer.datasets.get_mnist()\n",
        "\n",
        "train_iter = chainer.iterators.SerialIterator(train_dataset, batch_size)\n",
        "test_iter = chainer.iterators.SerialIterator(test_dataset, batch_size,    repeat=False, shuffle=False)\n",
        "\n",
        "updater = training.updaters.StandardUpdater( train_iter, optimizer, device=-1)\n",
        "trainer = training.Trainer(updater, (epoch_num, 'epoch'), out='result')\n",
        "\n",
        "trainer.extend(extensions.Evaluator(test_iter, model, device=-1))\n",
        "\n",
        "trainer.extend(extensions.dump_graph('main/loss'))\n",
        "\n",
        "trainer.extend(extensions.LogReport())\n",
        "\n",
        "trainer.extend(extensions.PlotReport(['main/loss', 'validation/main/loss'],  'epoch', file_name='loss.png'))\n",
        "trainer.extend(extensions.PlotReport(['main/accuracy', 'validation/main/accuracy'],'epoch', file_name='accuracy.png'))\n",
        "trainer.extend(extensions.PrintReport(['epoch', 'main/loss', 'validation/main/loss', 'main/accuracy', 'validation/main/accuracy', 'elapsed_time']))\n",
        "\n",
        "trainer.run()\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch       main/loss   validation/main/loss  main/accuracy  validation/main/accuracy  elapsed_time\n",
            "\u001b[J1           0.484195    0.273538              0.86805        0.9262                    3.90658       \n",
            "\u001b[J2           0.245821    0.206022              0.930267       0.942                     8.20671       \n",
            "\u001b[J3           0.192809    0.167739              0.944983       0.9517                    12.5594       \n",
            "\u001b[J4           0.159414    0.148014              0.953883       0.9578                    16.968        \n",
            "\u001b[J5           0.135661    0.132359              0.961          0.9611                    21.3317       \n",
            "\u001b[J6           0.118311    0.118049              0.967083       0.9663                    25.7479       \n",
            "\u001b[J7           0.10397     0.108935              0.97115        0.9685                    30.2563       \n",
            "\u001b[J8           0.0930871   0.102286              0.974033       0.9703                    34.6859       \n",
            "\u001b[J9           0.0843326   0.0967026             0.976217       0.9729                    39.1005       \n",
            "\u001b[J10          0.0767788   0.0911113             0.979          0.9732                    43.5345       \n",
            "\u001b[J11          0.069977    0.0876093             0.9811         0.975                     47.9138       \n",
            "\u001b[J12          0.0646995   0.0858919             0.982233       0.9749                    52.3263       \n",
            "\u001b[J13          0.0595774   0.0840762             0.984017       0.9753                    56.7269       \n",
            "\u001b[J14          0.0557333   0.0799696             0.985133       0.9755                    61.1332       \n",
            "\u001b[J15          0.0516605   0.0785341             0.986683       0.9771                    65.5288       \n",
            "\u001b[J16          0.048243    0.078662              0.987433       0.9747                    70.0286       \n",
            "\u001b[J17          0.044927    0.0758818             0.9887         0.9762                    74.4419       \n",
            "\u001b[J18          0.04241     0.0731264             0.989217       0.9776                    78.855        \n",
            "\u001b[J19          0.0397336   0.0732808             0.990283       0.978                     83.3683       \n",
            "\u001b[J20          0.0371044   0.0704797             0.990817       0.9782                    87.8618       \n",
            "\u001b[J21          0.0350298   0.0701013             0.992          0.9779                    92.3573       \n",
            "\u001b[J22          0.0329319   0.0682157             0.992183       0.9791                    96.8325       \n",
            "\u001b[J23          0.0311519   0.0678827             0.992667       0.9796                    101.249       \n",
            "\u001b[J24          0.0292564   0.0686527             0.993133       0.9784                    105.642       \n",
            "\u001b[J25          0.0278939   0.0677664             0.9941         0.9792                    110.051       \n",
            "\u001b[J26          0.0262026   0.0672132             0.994533       0.9795                    114.471       \n",
            "\u001b[J27          0.0248783   0.0679279             0.994783       0.979                     119.005       \n",
            "\u001b[J28          0.0233664   0.0671062             0.995383       0.9798                    123.432       \n",
            "\u001b[J29          0.0224686   0.0659223             0.99555        0.9797                    127.862       \n",
            "\u001b[J30          0.0213767   0.0643228             0.9957         0.9799                    132.286       \n",
            "\u001b[J31          0.0202926   0.0669681             0.996233       0.9797                    137.223       \n",
            "\u001b[J32          0.0191502   0.0652581             0.996733       0.9797                    142.122       \n",
            "\u001b[J33          0.0183853   0.0647769             0.996983       0.9797                    147.021       \n",
            "\u001b[J34          0.0174939   0.0641577             0.99745        0.9799                    151.717       \n",
            "\u001b[J35          0.0166219   0.0644749             0.9974         0.9807                    156.395       \n",
            "\u001b[J36          0.0158187   0.0666306             0.997883       0.98                      161.046       \n",
            "\u001b[J37          0.0151354   0.0651674             0.998067       0.9808                    165.709       \n",
            "\u001b[J38          0.0145553   0.0641089             0.997983       0.981                     170.133       \n",
            "\u001b[J39          0.0138939   0.0639033             0.99845        0.9806                    175.014       \n",
            "\u001b[J40          0.0132645   0.0640093             0.998567       0.9809                    180.014       \n",
            "\u001b[J41          0.0127026   0.0640716             0.9986         0.9812                    184.861       \n",
            "\u001b[J42          0.0121247   0.064481              0.998767       0.9804                    189.72        \n",
            "\u001b[J43          0.0116935   0.0660929             0.9989         0.9797                    194.359       \n",
            "\u001b[J44          0.0112246   0.0658342             0.998917       0.9802                    198.961       \n",
            "\u001b[J45          0.0108099   0.0640924             0.999067       0.981                     203.553       \n",
            "\u001b[J46          0.0104359   0.0651084             0.999167       0.9808                    207.974       \n",
            "\u001b[J47          0.00999082  0.0643494             0.99915        0.9804                    212.77        \n",
            "\u001b[J48          0.00966999  0.0637836             0.999183       0.9806                    217.544       \n",
            "\u001b[J49          0.00920545  0.0654388             0.999467       0.9806                    222.154       \n",
            "\u001b[J50          0.00887436  0.0643884             0.999417       0.9805                    226.769       \n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}